import numpy as np
import pandas as pd 
import os
import matplotlib.pyplot as plt
%matplotlib inline

import pydicom as pm

import cv2

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim

from tqdm import tqdm

device = torch.device('cuda')

path = "/kaggle/input/osic-pulmonary-fibrosis-progression/"

train_csv = pd.DataFrame(pd.read_csv(path + "train.csv"))
test_csv = pd.DataFrame(pd.read_csv(path + "test.csv"))
submission = pd.DataFrame(pd.read_csv(path + "sample_submission.csv"))
train_csv[:9]

len(train_csv) # 1549
len(test_csv) # 5 | test folder with CT scan images also contains 5 patients
train_csv.Patient[train_csv.Patient == 'ID00007637202177411956430']
print(test_csv)

list_of_scans = []
counter = 0
for dirname, _, filename in os.walk(path + "train/ID00007637202177411956430/"):
    for f in filename:
        img = pm.dcmread(path + "train/ID00007637202177411956430/" + f)
        list_of_scans.append([np.array(img.pixel_array, dtype = float),f[:2]])
        counter += 1

for i in range(len(list_of_scans)):
    plt.imshow(list_of_scans[i][0])
    plt.show()
    print(list_of_scans[i][1])

#print(list_of_scans[1][0].shape) # 512 by 512 np array

EPOCHS = 8
BATCH_SIZE = 100

class Net(nn.Module):
    
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 32, 5) #input, output, kernel size
        self.conv2 = nn.Conv2d(32, 64, 5)
        self.conv3 = nn.Conv2d(64, 128, 5)
        
        x = torch.randn(512, 512).view(-1, 1, 512, 512)
        self._to_linear = None
        self.convs(x)
        
        self.fc1 = nn.Linear(self._to_linear, 512)
        self.fc2 = nn.Linear(512, 2)
        
    def convs(self, x):
        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))
        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))
        x = F.max_pool2d(F.relu(self.conv3(x)), (2,2))
        
        #print(x[0].shape)
        if self._to_linear is None:
            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]
        return x
    
    def forward(self, x):
        x = self.convs(x)
        x = x.view(-1, self._to_linear)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.softmax(x, dim = 1)
    
net = Net().to(device)

optimizer = optim.Adam(net.parameters(), lr=0.001)
loss_func = nn.MSELoss() #or: CrossEntropyLoss


X = torch.Tensor([i[0] for i in list_of_scans]).view(-1, 512, 512)
X = X/255.0

y = torch.Tensor([int(i[1]) for i in list_of_scans]) # rework this line

VAL_PCT = 0.1
val_size = int(len(X)*VAL_PCT)
print(val_size)

train_X = X[:-val_size]
train_y = y[:-val_size]

test_X = X[-val_size:]
test_y = y[-val_size:]

def train(net):
    for epoch in range(EPOCHS):
        for i in range(0, len(train_X), BATCH_SIZE):
            batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50).to(device)
            batch_y = train_y[i:i+BATCH_SIZE].to(device)
            
            net.zero_grad()
            outputs = net(batch_X)
            loss = loss_func(outputs, batch_y)
            loss.backward()
            optimizer.step()
        
        print(f"Epoch: {epoch}. Loss: {loss}")
        
def test(net):
    correct = 0
    total = 0
    with torch.no_grad():
        for i in tqdm(range(len(test_X))):
            real_class = torch.argmax(test_y[i]).to(device)
            net_out = net(test_X[i].view(-1, 1, 50, 50).to(device))[0]
            net_out = net(test_X[i].view(-1, 1, 50, 50).to(device))[0]
            predicted_class = torch.argmax(net_out)
            if predicted_class == real_class:
                correct += 1
            total += 1
            submission_file.target[i] = predicted_class.item() 
            
    print("Accuracy: ", round(correct/total, 3))
    
train(net)

test(net) # out of sample test
#X[0]
